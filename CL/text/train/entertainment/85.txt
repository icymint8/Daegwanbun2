Use of AI to replicate James Earl Jones' voice of Darth Vader concerns actors
Over the course of an acting career that spanned more than six decades, James Earl Jones' voice became an indelible piece of his work as a performer. On screen, Jones, who died Monday at 93, brought to life a reclusive writer coaxed back into the spotlight in "Field of Dreams" and a haughty king of a fictional land in "Coming To America." On stage, he won two Tony Awards for "The Great White Hope" and "Fences." His work as a voice actor — the regal dignity of his portrayal of Mufasa in "The Lion King" and the menacing and deep timbre he lent to Darth Vader in "Star Wars" — helped cement his place as a legendary actor among generations of fans. But in the wake of his death, an aspect of Jones' career has come to the fore: consenting to the use of artificial intelligence to replicate his performance as Darth Vader after he stepped away from the role. Skywalker Sound and the Ukrainian company Respeecher used AI to recreate Jones' villain for the 2022 show "Obi-Wan Kenobi" on Disney+. Mark Hamill's voice was also "de-aged" using Respeecher for his appearance as Luke Skywalker in "The Mandalorian." Voice actors say they fear AI could reduce or eliminate job opportunities because the technology could be used to replicate one performance into a number of other movements without their consent — a concern that led video game performers with the Screen Actors Guild-American Federation of Television and Radio Artists to go on strike in late July. Hollywood's video game performers announced a work stoppage — their second in a decade — after more than 18 months of negotiations over a new interactive media agreement with game industry giants broke down over artificial intelligence protections. Members of the union have said they are not anti-AI. The performers are worried, however, the technology could provide studios with a means to displace them. Concerns about how movie studios will use AI helped fuel last year's film and television strikes by the union, which lasted four months. To some, Jones' decision to allow AI to replicate his voice raises questions about voice acting as an art, but also potentially helps lay the ground work for transparent AI agreements that fairly compensate an actor for their performance with consent. Zeke Alton, a voice actor and member of SAG-AFTRA's interactive media agreement negotiating committee, said it's "amazing" that Jones was involved in the process of replicating his voice. "If the game companies, the movie companies, gave the consent, compensation transparency to every actor that they gave James Earl Jones, we wouldn't be on strike," Alton said. "It proves that they can do it. They just don't want to for people that they feel don't have the leverage to bargain for themselves." Jones, who overcame a childhood stutter, said in previous interviews that he was "happy to be able to talk at all, because there was time when I couldn't." His goal, he said, was for his voice to be clear. Speaking with The Associated Press in 1994, he said that he tried to make Darth Vader "more human and more interesting." But George Lucas, the filmmaker who created "Star Wars," advised him to "go back to a very narrow band of expression" because the mechanical parts of the villain's body would make it difficult for him to sound more human. Neither Skywalker Sound nor Respeecher responded to a request for comment. But a sound editor with Skywalker Sound told Vanity Fair that Jones signed off on the use of archival recordings to keep Darth Vader alive and that he guided Darth Vader's performance for the Disney+ show as "a benevolent godfather." Voice actor Brock Powell said that the ability to use an actor like Jones' voice in perpetuity could eliminate the need for actors who specialize in matching voices. That type of work provides steady jobs for many performers, they said, who can recreate a famous voice for video games, animated series and other types of media.  "To quote 'Jurassic Park,' the scientists were so preoccupied with whether or not they could, they didn't stop to ask if we should," Powell said. That type of AI use could also reduce "ingenuity" in acting, they said, because new actors might not have the chance to come in and reinvigorate a role.  Crispin Freeman, an actor who has done voice matching work replicating Orlando Bloom's voice in "Pirates of the Caribbean," said that the technology may take away voice matching roles, but doesn't harm "the ability of future artists to blaze their own trails" in new roles. "We always need to keep reinventing new stories as we're going forward, and not simply relying on the old stuff," he said. "Rather than worrying, 'Oh, will someone else be able to be Darth Vader,' why don't we make a new 'Star Wars' character that's as compelling as Darth Vader?" Jones' contract could set an example of properly bargaining with an actor over their likeness, said Sarah Elmaleh, chair of SAG-AFTRA's interactive negotiating committee. Elmaleh, a voice actor, said there is a chance for these tools to be used in "meaningful, smart artistic decisions." "I worry about a world where we conflate the superficial qualities of a person's voice with their performance," she said. "I can't help getting away from the metaphor that's baked into this character itself, which is, when you conflate the man with the machine, you become a tool for other forces, other powers that be." Alton, the voice actor, said he wonders about what the use of Jones' voice as Darth Vader would mean if it were used for another 100 years and people didn't remember "all of the different things that built him into the iconic character that he was." "It's just a disembodied voice at that point. It's part of the neutering of art that generative AI has the potential to do, and it's sort of a heady subject, but it's very important for us as a world to consider what we want our entertainment and our art to be in the future," he said. "Do we want it to be human, or do we want it to be bland?".